\documentclass[11pt]{article}
\usepackage{xeCJK}
\usepackage[a4paper, margin=1.4in]{geometry}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[most]{tcolorbox}
\usepackage{framed} 
\usepackage{tikz}
\usepackage{hyperref}

\linespread{1.25}
\setlength\parindent{0pt}

\title{%
  \LARGE
  \textbf{COMP90086 Computer Vision \\
  \large Week 3
  \\
  Light, Shadow and Edges}}
\author{ Lecture Notes summarized by Neo }
\date{Semester 2 2021}

\pagestyle{fancy}
\fancyhf{}
\rhead{COMP90086 Computer Vision}
\lhead{Lecture Notes}
\rfoot{Page \thepage}

\begin{document}

\maketitle

\section{Image Formation}

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.8\textwidth]{image_formation.png}
    \caption{Image formation model}
\end{figure}
\subsection{Diffuse (Lambertian) reflectance æ¼«åå°„ï¼ˆæ¼«å°„ï¼‰}
è¡¨é¢ä¸€èˆ¬ä¸ºç²—ç³™çš„ã€‚
\begin{Large}
    $$I_D(x)=I_LRN(x)\cdot L$$
\end{Large}
where
\begin{itemize}
    \item $I_D$ is the Intensity of reflected light
    \item $I_L$ is the light source intensity (åœ¨CVå¤„ç†ä¸­å¸¸å¿½ç•¥)
    \item $R$ is the surface colour (reflectance)
    \item $N(x)$ is the surface normal vector
    \item $L$ is the vector to light source
\end{itemize}

\begin{framed}
    \begin{center}
        The goal is to recover \textbf{both} the surface colour and the normal vector given the reflected light.
    \end{center}
\end{framed}

\section{Colour}
\subsection{Visible Light}
\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{visible_light.png}
    \caption{Visible light spectrum}
\end{figure}
é¢‘çŽ‡ä¸Žæ³¢é•¿æˆåæ¯”ï¼Œé¢‘çŽ‡è¶Šå¤§é¢œè‰²è¶Šå†·ï¼Œè¶Šå°è¶Šæš–ã€‚

\subsection{Perceived Colour}
å¤§éƒ¨åˆ†äººç±»çš„è§†ç½‘è†œä¸Šæœ‰\textbf{ä¸‰ç§}æ„ŸçŸ¥é¢œè‰²çš„æ„Ÿå…‰ç»†èƒžï¼Œå«åšè§†é”¥ç»†èƒžï¼Œåˆ†åˆ«å¯¹ä¸åŒæ³¢é•¿çš„å…‰çº¿æ•æ„Ÿï¼Œç§°ä¸º L/M/S åž‹ç»†èƒžã€‚ä¸‰ç§è§†é”¥ç»†èƒžæœ€æ•æ„Ÿçš„æ³¢é•¿åˆ†åˆ«æ˜¯æ©™çº¢è‰²ï¼ˆé•¿æ³¢ï¼ŒLongï¼‰ï¼Œç»¿è‰²ï¼ˆä¸­æ³¢ï¼ŒMediumï¼‰ï¼Œè“è‰²ï¼ˆçŸ­æ³¢ï¼ŒShortï¼‰ã€‚è¿™ä¸‰ç§è§†é”¥ç»†èƒžçš„å½’ä¸€åŒ–æ„Ÿå…‰æ›²çº¿å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\footnote{https://zhuanlan.zhihu.com/p/24214731}

ä¸–ç•Œä¸Šæ‰€æœ‰é¢œè‰²ï¼Œåœ¨äººç±»çš„çœ¼é‡Œçœ‹åˆ°ï¼Œæœ€åŽä¼ é€åˆ°å¤§è„‘é‡Œçš„ä¿¡å·ï¼Œå°±åªæœ‰è¿™ä¸‰ç§è§†é”¥ç»†èƒžçš„ç”µä¿¡å·è€Œå·²ã€‚æ ¹æ®è¿™ä¸‰ç§ç”µä¿¡å·çš„å¼ºå¼±ï¼Œå¤§è„‘è§£è¯»æˆäº†ä¸åŒçš„é¢œè‰²ã€‚
\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.8\textwidth]{perceived.png}
    \caption{Light response spectra of human eyes}
\end{figure}

\begin{framed}
    \begin{center}
        ä¸–ç•Œä¸Šæ¯ä¸€ç§é¢œè‰²éƒ½æ˜¯è¿™ä¸‰ç§ç”µä¿¡å·çš„ç»„åˆï¼Œå¹¶ä¸”åŒæ ·çš„é¢œè‰²ä¼šæœ‰æ— æ•°ç§ä¸‰ç§ç”µä¿¡å·ç»„åˆçš„æ–¹å¼ã€‚
    \end{center}
\end{framed}

\subsubsection*{Sensor Response (Perceived value of light)}
\begin{itemize}
    \item $I_R=\int_{700}^{400}I(\lambda)S_R(\lambda)\, \partial \lambda$
    \item $I_G=\int_{700}^{400}I(\lambda)S_G(\lambda)\, \partial \lambda$
    \item $I_B=\int_{700}^{400}I(\lambda)S_B(\lambda)\, \partial \lambda$
\end{itemize}

ä¸‹å›¾ä¸ºä¸€ä¸ªä¾‹å­ï¼šä¸Šé¢çš„å›¾ä»£è¡¨Spectrumï¼Œäº§å‡ºç›¸åŒçš„é¢œè‰²ã€‚ï¼ˆè¯¯å·®ä¸å¥½æŽ§åˆ¶ï¼‰
\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{diff1.png}
\end{figure}
\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{diff2.png}
    \caption{Different spectrum, same colour}
\end{figure}

\newpage
\subsection{Colour Representation}
å¸¸è§çš„é¢œè‰²è¡¨ç¤ºæ–¹å¼ï¼š
\begin{itemize}
    \item RGBï¼ˆæ³¨æ„æœ‰ä¸åŒç‰ˆæœ¬çš„RGBå®šä¹‰ï¼‰
    \item HSL/HSV (Hueè‰²ç›¸ Saturationé¥±å’Œåº¦ Lightnessäº®åº¦/Valueæ˜Žåº¦)
    \item CIE 1931 XYZï¼ˆColourmatch RGBï¼‰
    \item LAB (luminance, a*=red/green, b*=blue/yellow)
\end{itemize}
\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.88\textwidth]{colour_space.png}
    \caption{Colour spaces}
\end{figure}


\subsection{Colour Transforms}
ç”±äºŽ CIE XYZ ç©ºé—´æ˜¯ä¸€ä¸ªå¾ˆæ–¹ä¾¿çš„çº¿æ€§ç©ºé—´ï¼Œä¸Žå…·ä½“è®¾å¤‡æ— å…³ï¼Œå› æ­¤å¸¸ç”¨æ¥åšå„ç§é¢œè‰²ç©ºé—´è½¬æ¢çš„ä¸­é—´åª’ä»‹ã€‚è®¾æƒ³æŸä¸ªé¢œè‰²çš„å…‰ï¼Œç»è¿‡è‰²åŒ¹é…å‡½æ•°çš„è®¡ç®—ï¼Œå¾—åˆ°äº†ä¸‰ä¸ª XYZ çš„å€¼ï¼Œå¦‚æžœç›´æŽ¥å°†è¿™ä¸‰ä¸ªå€¼ä½œä¸º RGB é¢œè‰²æ˜¾ç¤ºåˆ°å±å¹•ä¸Šï¼Œæ˜¾ç„¶æ˜¯ä¸å¯¹çš„ã€‚æˆ‘ä»¬å¿…é¡»æŠŠ XYZ çš„å€¼è½¬æ¢åˆ°å±å¹•çš„ RGB ç©ºé—´ä¸­çš„å€¼ã€‚åä¹‹åŒç†ã€‚\\(built-in functions in OpenCV)
$$\left[\begin{matrix}X\\Y\\Z\end{matrix}\right]=M\ \left[\begin{matrix}R\\G\\B\end{matrix}\right]$$

\newpage
è‰²è°±å›¾çš„æž„é€ å®žçŽ°ï¼ˆè¶…çº²ï¼‰ï¼š\url{https://zhuanlan.zhihu.com/p/24281841}
\subsection{Colour Swap}
ä¸è¦åœ¨RGB Spaceä¸­ç›´æŽ¥äº¤æ¢é¢œè‰²å› ä¸º\textbf{äº®åº¦}ä¸Žé¢œè‰²åœ¨RGBé‡Œæœ‰è”ç³»ï¼Œç›´æŽ¥äº¤æ¢ä¼šå¯¼è‡´äº®åº¦ä¸ç»Ÿä¸€ã€‚\textbf{è½¬åŒ–æˆLAB Spaceä¼šæœ‰æ›´å¥½çš„ç»“æžœ}ï¼Œå› ä¸ºäº®åº¦ä¸Žé¢œè‰²åˆ†ç¦»ã€‚


\section{Shading and Surfaces}
\subsection{Recovering Surface Normal}
Assume no changes in surface colour..
$$I_D(x)=N(x)\cdot L=\cos \theta_x$$

Can only recover angle between surface normal and light source, but not normal
\\
However, can add additional assumptions:
\begin{itemize}
    \item Normals along boundary of object are known
    \item Neighbouring normal are similar
\end{itemize}
\begin{framed}
    \begin{center}
        å·²çŸ¥çš„æ¡ä»¶ä¸è¶³ä»¥æŽ¨æ–­å‡ºSurface Normal Vectorï¼Œåªèƒ½è®¡ç®—å‡ºNormalå’Œå…‰æºçš„å¤¹è§’ã€‚è®¡ç®—Normalé€šå¸¸éœ€è¦å¤§é‡çš„Assumptionï¼Œå› ä¸ºäººçœ¼åšäº†å¤§éƒ¨åˆ†Assumptionæ‰€ä»¥å¯ä»¥æŽ¨æ–­å‡ºç‰©ä½“çš„â€œSurfaceâ€ã€‚
    \end{center}
\end{framed}
\subsection{Recovering Surface Reflectance}
\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{lum.png}
\end{figure}
\subsubsection{Simple Approach}
Simple approach: assume illumination variation
produces low spatial frequency changes in image,
remove illumination in frequency domain.
\begin{enumerate}
    \item $L=R\times I$
    \item $\ln (L)=\ln (R) + \ln (I)$
    \item $FT(\ln (L))=FT(\ln (R)) + FT(\ln (I))$
    \item Apply a high pass filter ð‘”in the frequency domain
    \item $Image=e^{FT^{-1}(g\times FT(\ln (L)))}$
\end{enumerate}

\subsubsection{Problems}
\begin{itemize}
    \item Some reflectance edges are smooth
    \item Some lighting edges are not smooth (textures, corners)
\end{itemize}
More sophisticated approaches (e.g., based on
partial differential equations) can give better
results but have similar problems.
\begin{framed}
    \begin{center}
        Lighting usually isn't uniform and most surfaces aren't matte/Lambertian.
    \end{center}
\end{framed}

\section{Edge Detection}
Edges are caused by a variety of factors:
\begin{itemize}
    \item Surface normal discontinuityï¼ˆè¡¨é¢è§’åº¦å˜åŒ–ï¼‰
    \item Depth discontinuity (change in depth but not in colour)
    \item Surface colour discontinuity
    \item Illumination discontinuityï¼ˆæŠ•å°„é˜´å½±ï¼Œå¸¸å¿½ç•¥ï¼‰
\end{itemize}



\begin{framed}
    \begin{center}
        Edges are points in the image with a high change in intensity = high change in gradient.
    \end{center}
\end{framed}



\subsection{Canny Algorithm}
The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. Canny also produced a computational theory of edge detection explaining why the technique works.
\begin{itemize}
    \item Noice reduction
    \item Gradient calculation
    \item Non-maximum Suppression
    \item Double threshold
    \item Edge Tracking by Hysteresis
\end{itemize}

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.8\textwidth]{canny.png}
    \caption{Original image on the left and final image on the right}
\end{figure}

\subsubsection{Noise Reduction}
Since the mathematics involved behind the scene are mainly based on derivatives
(cf. Step 2: Gradient calculation),
edge detection results are highly sensitive to image noise.
One way to get rid of the noise on the image,
is by applying Gaussian blur to smooth it.
To do so, image convolution technique is applied with a
Gaussian Kernel (3x3, 5x5, 7x7 etcâ€¦).
The kernel size depends on the expected blurring effect.
Basically, the smallest the kernel, the less visible is the blur.
\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.7\textwidth]{canny1.png}
    \caption{Processed with noice reduction}
\end{figure}


\subsubsection{Gradient Calculation}
The Gradient calculation step detects the edge intensity and direction by calculating the gradient of the image using edge detection operators.
\begin{framed}
    \begin{center}
        Edges correspond to a change of pixelsâ€™ intensity. To detect it, the easiest way is to apply filters that highlight this intensity change in both directions: horizontal ($x$) and vertical ($y$).
    \end{center}
\end{framed}

When the image is smoothed, the derivatives $I_x$ and $I_y$ w.r.t. $x$ and $y$ are calculated. It can be implemented by convolving I with Sobel kernels $K_x$ and $K_y$, respectively:

$$K_x=\left[\begin{matrix}-1&0&1\\-2&0&2\\-1&0&1\end{matrix}\right],\ K_y=\left[\begin{matrix}1&2&1\\0&0&0\\-1&-2&-1\end{matrix}\right]$$

Then, the magnitude $G$ and the slope $\theta$ of the gradient are calculated as follow:
$$\left|G\right|=\sqrt{I_x^2+I_y^2},$$
$$\theta\left(x,\ y\right)=\arctan\left(\frac{I_y}{I_x}\right)$$

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.7\textwidth]{canny2.png}
    \caption{Processed with gradient calculation}
\end{figure}


The result is almost the expected one, but we can see that some of the edges are thick and others are thin. Non-Max Suppression step will help us mitigate the thick ones.

Moreover, the gradient intensity level is between 0 and 255 which is not uniform. The edges on the final result should have the same intensity (i-e. white pixel = 255).


\subsubsection{Non-Maximum Suppression}
Ideally, the final image should have thin edges. Thus, we must perform non-maximum suppression to thin out the edges.

The principle is simple: maximum suppression: If nearby pixels claim to be
part of the same edge, only keep the one with
maximum gradient.

å¦‚æžœåŽŸå›¾åƒæœ‰æ¸å˜è¿‡æ¥çš„è¾¹ç•Œç®—æ³•å¯èƒ½ä¼šè®¡ç®—å‡ºå¾ˆç²—çš„è¾¹ç•Œï¼ˆå¾ˆå¤šä¸ªè¿žåœ¨ä¸€èµ·ï¼‰ï¼Œä¸ºäº†ä¿è¯è¾¹ç•Œç²—ç»†ç»Ÿä¸€æˆ‘ä»¬ä½¿ç”¨Non-Maximum Suppressionã€‚

\begin{itemize}
    \item Bin edges by orientation
    \item For each edge pixel:
          \begin{enumerate}
              \item Check the two neighbour pixels orthogonal to this edge pixel,
              \item If either neighbour has same edge orientation AND higher magnitude, this pixel is not an edge.
          \end{enumerate}
\end{itemize}

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.7\textwidth]{canny3.png}
    \caption{Processed with non-maximum suppression}
\end{figure}

The result is the same image with thinner edges. We can however still notice some variation regarding the edgesâ€™ intensity: some pixels seem to be brighter than others, and we will try to cover this shortcoming with the two final steps.


\subsubsection{Thresholding with hysteresis (combined the last two steps)}
\begin{itemize}
    \item Two thresholds $T_1, T_2$ with $T_1 > T_2$
    \item Strong edges: magnitude $> T_1$
    \item Weak edges: $T_1 >$ magnitude $> T_2$
    \item For each weak edge:
          \begin{enumerate}
              \item Check the 8 pixel neighbourhood around this pixel
              \item If any neighbour is a strong edge, relabel the weak edge
                    pixel as a strong edge
          \end{enumerate}
    \item Final edge map = strong edges
\end{itemize}

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=0.8\textwidth]{canny4.png}
    \caption{Processed with thresholding with hysteresis}
\end{figure}


\section{Image Recognition}
\subsection{Compression}
\begin{itemize}
    \item Edge = discontinuity
    \item Efficient way to represent images: only represent points
          where the signal changes (e.g., Elder \& Zucker, 1996)
\end{itemize}

\subsection{Invariance}
\begin{itemize}
    \item Edge based features are invariant or tolerant to many
          irrelevant image changes
    \item Invariant to $X$ = response/representation does not
          vary with $X$, is insensitive to changes in $X$
    \item Tolerant to $X$ = response is mostly insensitive to $X$
\end{itemize}

\subsection{Image Recognition}
More on next weeks...

\subsection{Hough transform}
......



\end{document}
